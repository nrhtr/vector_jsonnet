{
  sources:: {
    fn(type, o):: { kind:: 'sources', type: type } + o,

    // The Vector apache_metrics source collects metrics from Apache HTTP server (HTTPD).
    apache_metrics(o={}):: self.fn('apache_metrics', o),

    // The ECS metrics source collects the docker container stats for tasks running in Amazon ECS or Fargate.
    aws_ecs_metrics(o={}):: self.fn('aws_ecs_metrics', o),

    // AWS Kinesis Firehose is an AWS service that simplifies dealing with streaming data. It allows for ingestion, transformation, and forwarding of events. In addition to publishing events directly to Kinesis Firehose, the service has direct integrations with many AWS services which allow them to directly publish events to a delivery stream.
    aws_kinesis_firehose(o={}):: self.fn('aws_kinesis_firehose', o),

    // Amazon Simple Storage Service (Amazon S3) is a scalable, high-speed, web-based cloud storage service designed for online backup and archiving of data and applications on Amazon Web Services. It is very commonly used to store log data.
    aws_s3(o={}):: self.fn('aws_s3', o),

    // Test.
    docker_logs(o={}):: self.fn('docker_logs', o),

    // The Vector file source collects logs from files.
    file(o={}):: self.fn('file', o),

    // The Vector generator source generates logs
    generator(o={}):: self.fn('generator', o),

    // The host metrics source examines system data sources on the local system and generates metrics describing utilization of various system resources.
    host_metrics(o={}):: self.fn('host_metrics', o),

    // The Vector http source receives logs from HTTP.
    http(o={}):: self.fn('http', o),

    // The internal metrics source exposes metrics emitted by the running Vector instance (as opposed to components in its topology).
    internal_metrics(o={}):: self.fn('internal_metrics', o),

    // Journald is a utility for accessing log data across a variety of system services. It was introduced with Systemd to help system administrators collect, access, and route log data.
    journald(o={}):: self.fn('journald', o),

    // Apache Kafka is an open-source project for a distributed publish-subscribe messaging system rethought as a distributed commit log. Kafka stores messages in topics that are partitioned and replicated across multiple brokers in a cluster. Producers send messages to topics from which consumers read. These features make it an excellent candidate for durably storing logs and metrics data.
    kafka(o={}):: self.fn('kafka', o),

    // The Vector kubernetes_logs source collects logs from Kubernetes.
    kubernetes_logs(o={}):: self.fn('kubernetes_logs', o),

    // Herokuâ€™s Logplex router is responsible for collating and distributing the log entries generated by Heroku apps and other components of the Heroku platform. It makes these entries available through the Logplex public API and the Heroku command-line tool.
    logplex(o={}):: self.fn('logplex', o),

    // MongoDB is a general purpose, document-based, distributed database built for modern application developers and for the cloud era.
    mongodb_metrics(o={}):: self.fn('mongodb_metrics', o),

    // Nginx is an HTTP and reverse proxy server, a mail proxy server, and a generic TCP/UDP proxy server.
    nginx_metrics(o={}):: self.fn('nginx_metrics', o),

    // The Prometheus remote_write protocol is a protobuf based encoding for sending metrics efficiently between agents.
    prometheus_remote_write(o={}):: self.fn('prometheus_remote_write', o),

    // Prometheus is a pull-based monitoring system that scrapes metrics from configured endpoints, stores them efficiently, and supports a powerful query language to compose dynamic information from a variety of otherwise unrelated data points.
    prometheus_scrape(o={}):: self.fn('prometheus_scrape', o),

    // The Vector socket source receives logs from socket client.
    socket(o={}):: self.fn('socket', o),

    // The Splunk HTTP Event Collector (HEC) is a fast and efficient way to send data to Splunk Enterprise and Splunk Cloud. Notably, HEC enables you to send data over HTTP (or HTTPS) directly to Splunk Enterprise or Splunk Cloud from your application.
    splunk_hec(o={}):: self.fn('splunk_hec', o),

    // StatsD is a standard and, by extension, a set of tools that can be used to send, collect, and aggregate custom metrics from any application. Originally, StatsD referred to a daemon written by Etsy in Node.
    statsd(o={}):: self.fn('statsd', o),

    // The Vector stdin source receives logs from STDIN.
    stdin(o={}):: self.fn('stdin', o),

    // Syslog stands for System Logging Protocol and is a standard protocol used to send system log or event messages to a specific server, called a syslog server. It is used to collect various device logs from different machines and send them to a central location for monitoring and review.
    syslog(o={}):: self.fn('syslog', o),

    // The Vector vector source receives logs from Vector.
    vector(o={}):: self.fn('vector', o),
  },
}
